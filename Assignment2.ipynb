{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_methods import print_schema, encode_numeric_zscore, encode_text_dummy, print_column, encode_text_index, to_xy, plot_losses\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ea03e",
   "metadata": {},
   "source": [
    "### Define Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366e7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1d33f",
   "metadata": {},
   "source": [
    "### Setup Environment\n",
    "Create folders for putting test output in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed3197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably safe to ignore the following error: \n",
      "[WinError 183] Cannot create a file when that file already exists: 'c:\\\\Users\\\\User\\\\csc180\\\\network-traffic-analyzer\\\\test-output/'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'c:\\\\Users\\\\User\\\\csc180\\\\network-traffic-analyzer\\\\test-output/iteration-1'\n"
     ]
    }
   ],
   "source": [
    "base_path=os.path.join(os.getcwd(), 'test-output/')\n",
    "\n",
    "iteration='iteration-2'\n",
    "full_path = os.path.join(base_path, iteration)\n",
    "try:\n",
    "        os.mkdir(base_path)\n",
    "except Exception as e:\n",
    "     print(f\"Probably safe to ignore the following error: \\n{e}\")\n",
    "try:\n",
    "    os.mkdir(full_path)\n",
    "except Exception as e:\n",
    "    print(f\"{e}\\nExiting to protect previous work.\")\n",
    "    sys.exit(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2447f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from train/test datasets\n",
    "training_dataframe = pd.read_csv(os.path.join(os.getcwd(), 'data/UNSW_NB15_training-set.csv'))\n",
    "testing_dataframe = pd.read_csv(os.path.join(os.getcwd(), 'data/UNSW_NB15_testing-set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413f56ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all entries that have a missing value anywhere in the set\n",
    "training_dataframe = training_dataframe.replace('-', np.nan).dropna()\n",
    "testing_dataframe = testing_dataframe.replace('-', np.nan).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd24337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35179, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60380dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get one instance of each value from each dataframe\n",
    "training_unique = training_dataframe[\"proto\"].unique()\n",
    "testing_unique = testing_dataframe[\"proto\"].unique()\n",
    "\n",
    "#get only values from each numpy array\n",
    "common_values = np.intersect1d(training_unique, testing_unique)\n",
    "\n",
    "#make a filtered dataframe containing only values in common_values\n",
    "training_dataframe = training_dataframe[training_dataframe['proto'].isin(common_values)]\n",
    "testing_dataframe = testing_dataframe[testing_dataframe['proto'].isin(common_values)]\n",
    "\n",
    "#same for service\n",
    "training_unique = training_dataframe[\"service\"].unique()\n",
    "testing_unique = testing_dataframe[\"service\"].unique()\n",
    "common_values = np.intersect1d(training_unique, testing_unique)\n",
    "training_dataframe = training_dataframe[training_dataframe['service'].isin(common_values)]\n",
    "testing_dataframe = testing_dataframe[testing_dataframe['service'].isin(common_values)]\n",
    "\n",
    "#same for state\n",
    "training_unique = training_dataframe[\"state\"].unique()\n",
    "testing_unique = testing_dataframe[\"state\"].unique()\n",
    "common_values = np.intersect1d(training_unique, testing_unique)\n",
    "training_dataframe = training_dataframe[training_dataframe['state'].isin(common_values)]\n",
    "testing_dataframe = testing_dataframe[testing_dataframe['state'].isin(common_values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee37ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35178, 45)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38ff501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~dataframe schema~~~~~~\n",
      "Dataframe shape: (81159, 45) | Dataframe length: 81159\n",
      "Column labels: \n",
      "Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
      "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
      "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
      "      dtype='object')\n",
      "Dataframe head: \n",
      "    id       dur proto service  ... ct_srv_dst  is_sm_ips_ports  attack_cat  label\n",
      "3    4  1.681642   tcp     ftp  ...          1                0      Normal      0\n",
      "11  12  2.093085   tcp    smtp  ...          1                0      Normal      0\n",
      "15  16  0.000002   udp    snmp  ...          1                0      Normal      0\n",
      "17  18  0.393556   tcp    http  ...          3                0      Normal      0\n",
      "21  22  0.338017   tcp    http  ...          3                0      Normal      0\n",
      "\n",
      "[5 rows x 45 columns]\n",
      "~~~~~~dataframe schema~~~~~~\n",
      "Dataframe shape: (35178, 45) | Dataframe length: 35178\n",
      "Column labels: \n",
      "Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
      "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
      "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
      "      dtype='object')\n",
      "Dataframe head: \n",
      "    id       dur proto service  ... ct_srv_dst  is_sm_ips_ports  attack_cat  label\n",
      "35  36  0.983874   tcp    http  ...          3                0      Normal      0\n",
      "40  41  1.535254   tcp    http  ...          3                0      Normal      0\n",
      "45  46  1.059359   tcp    http  ...          1                0      Normal      0\n",
      "49  50  0.990548   tcp    http  ...          2                0      Normal      0\n",
      "72  73  1.303518   tcp    http  ...          1                0      Normal      0\n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "print_schema(training_dataframe)\n",
    "print_schema(testing_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1ae45",
   "metadata": {},
   "source": [
    "### Encode Data\n",
    "\n",
    "One-hot encode relevant rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9c73bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Backdoor', 'DoS', 'Exploits', 'Fuzzers', 'Generic', 'Normal',\n",
       "       'Reconnaissance', 'Worms'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode non-y features of training dataset\n",
    "encode_text_dummy(training_dataframe, 'proto')\n",
    "encode_text_dummy(training_dataframe, 'service')\n",
    "encode_text_dummy(training_dataframe, 'state')\n",
    "\n",
    "# one-hot encode attack-category column (y)\n",
    "encode_text_index(training_dataframe, 'attack_cat')\n",
    "# one-hot encode non-y features of testing dataset\n",
    "encode_text_dummy(testing_dataframe, 'proto')\n",
    "encode_text_dummy(testing_dataframe, 'service')\n",
    "encode_text_dummy(testing_dataframe, 'state')\n",
    "\n",
    "# one-hot encode attack-category column (y)\n",
    "\n",
    "encode_text_index(testing_dataframe, 'attack_cat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff30683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~dataframe schema~~~~~~\n",
      "Dataframe shape: (81159, 60) | Dataframe length: 81159\n",
      "Column labels: \n",
      "Index(['id', 'dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl',\n",
      "       'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit',\n",
      "       'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat',\n",
      "       'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src',\n",
      "       'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm',\n",
      "       'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd',\n",
      "       'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label',\n",
      "       'proto-tcp', 'proto-udp', 'service-dhcp', 'service-dns', 'service-ftp',\n",
      "       'service-ftp-data', 'service-http', 'service-irc', 'service-pop3',\n",
      "       'service-radius', 'service-smtp', 'service-snmp', 'service-ssh',\n",
      "       'service-ssl', 'state-CON', 'state-FIN', 'state-INT', 'state-REQ'],\n",
      "      dtype='object')\n",
      "Dataframe head: \n",
      "    id       dur  spkts  dpkts  ...  state-CON  state-FIN  state-INT  state-REQ\n",
      "3    4  1.681642     12     12  ...      False       True      False      False\n",
      "11  12  2.093085     62     28  ...      False       True      False      False\n",
      "15  16  0.000002      2      0  ...      False      False       True      False\n",
      "17  18  0.393556     10      8  ...      False       True      False      False\n",
      "21  22  0.338017     10      6  ...      False       True      False      False\n",
      "\n",
      "[5 rows x 60 columns]\n",
      "~~~~~~dataframe schema~~~~~~\n",
      "Dataframe shape: (35178, 60) | Dataframe length: 35178\n",
      "Column labels: \n",
      "Index(['id', 'dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl',\n",
      "       'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit',\n",
      "       'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat',\n",
      "       'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src',\n",
      "       'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm',\n",
      "       'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd',\n",
      "       'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label',\n",
      "       'proto-tcp', 'proto-udp', 'service-dhcp', 'service-dns', 'service-ftp',\n",
      "       'service-ftp-data', 'service-http', 'service-irc', 'service-pop3',\n",
      "       'service-radius', 'service-smtp', 'service-snmp', 'service-ssh',\n",
      "       'service-ssl', 'state-CON', 'state-FIN', 'state-INT', 'state-REQ'],\n",
      "      dtype='object')\n",
      "Dataframe head: \n",
      "    id       dur  spkts  dpkts  ...  state-CON  state-FIN  state-INT  state-REQ\n",
      "35  36  0.983874     10      8  ...      False       True      False      False\n",
      "40  41  1.535254     10     10  ...      False       True      False      False\n",
      "45  46  1.059359     10      8  ...      False       True      False      False\n",
      "49  50  0.990548     10     10  ...      False       True      False      False\n",
      "72  73  1.303518     12      8  ...      False       True      False      False\n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "print_schema(training_dataframe)\n",
    "print_schema(testing_dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603761a",
   "metadata": {},
   "source": [
    "Z-Score relevant rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14acd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in training_dataframe.columns:\n",
    "    if column not in ['service', 'srcip', 'dstip', 'proto', 'state','service', 'attack_cat', 'label', 'is_ftp_login', 'is_sm_ips_ports', 'Stime', 'Ltime']:\n",
    "        encode_numeric_zscore(training_dataframe, column)\n",
    "for column in testing_dataframe.columns:\n",
    "    if column not in ['service', 'srcip', 'dstip', 'proto', 'state','service', 'attack_cat', 'label', 'is_ftp_login', 'is_sm_ips_ports', 'Stime', 'Ltime']:\n",
    "        encode_numeric_zscore(testing_dataframe, column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0322d511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~dataframe schema~~~~~~\n",
      "Dataframe shape: (81159, 60) | Dataframe length: 81159\n",
      "Column labels: \n",
      "Index(['id', 'dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl',\n",
      "       'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit',\n",
      "       'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat',\n",
      "       'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src',\n",
      "       'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm',\n",
      "       'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd',\n",
      "       'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label',\n",
      "       'proto-tcp', 'proto-udp', 'service-dhcp', 'service-dns', 'service-ftp',\n",
      "       'service-ftp-data', 'service-http', 'service-irc', 'service-pop3',\n",
      "       'service-radius', 'service-smtp', 'service-snmp', 'service-ssh',\n",
      "       'service-ssl', 'state-CON', 'state-FIN', 'state-INT', 'state-REQ'],\n",
      "      dtype='object')\n",
      "Dataframe head: \n",
      "          id       dur     spkts  ...  state-FIN  state-INT  state-REQ\n",
      "3  -1.930145  0.176161 -0.047987  ...   1.188510  -0.975659  -0.053077\n",
      "11 -1.929998  0.267844  0.216817  ...   1.188510  -0.975659  -0.053077\n",
      "15 -1.929924 -0.198559 -0.100948  ...  -0.841379   1.024935  -0.053077\n",
      "17 -1.929887 -0.110864 -0.058579  ...   1.188510  -0.975659  -0.053077\n",
      "21 -1.929814 -0.123239 -0.058579  ...   1.188510  -0.975659  -0.053077\n",
      "\n",
      "[5 rows x 60 columns]\n",
      "~~~~~~dataframe schema~~~~~~\n",
      "Dataframe shape: (35178, 60) | Dataframe length: 35178\n",
      "Column labels: \n",
      "Index(['id', 'dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl',\n",
      "       'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit',\n",
      "       'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat',\n",
      "       'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src',\n",
      "       'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm',\n",
      "       'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd',\n",
      "       'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label',\n",
      "       'proto-tcp', 'proto-udp', 'service-dhcp', 'service-dns', 'service-ftp',\n",
      "       'service-ftp-data', 'service-http', 'service-irc', 'service-pop3',\n",
      "       'service-radius', 'service-smtp', 'service-snmp', 'service-ssh',\n",
      "       'service-ssl', 'state-CON', 'state-FIN', 'state-INT', 'state-REQ'],\n",
      "      dtype='object')\n",
      "Dataframe head: \n",
      "          id       dur     spkts  ...  state-FIN  state-INT  state-REQ\n",
      "35 -1.686107  0.151343 -0.044029  ...   1.251327   -1.04209  -0.013061\n",
      "40 -1.685863  0.357138 -0.044029  ...   1.251327   -1.04209  -0.013061\n",
      "45 -1.685618  0.179517 -0.044029  ...   1.251327   -1.04209  -0.013061\n",
      "49 -1.685423  0.153834 -0.044029  ...   1.251327   -1.04209  -0.013061\n",
      "72 -1.684299  0.270646 -0.031874  ...   1.251327   -1.04209  -0.013061\n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "print_schema(training_dataframe)\n",
    "print_schema(testing_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05ae959",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=to_xy(training_dataframe, 'label')\n",
    "x_test, y_test=to_xy(testing_dataframe, 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484be713",
   "metadata": {},
   "source": [
    "### Create Fully Connected Model\n",
    "Design the model's architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb8ee546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\lab01\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1269/1269 - 4s - 3ms/step - loss: 0.1703 - val_loss: 0.2562\n",
      "Epoch 2/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0359 - val_loss: 0.2309\n",
      "Epoch 3/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0207 - val_loss: 0.2178\n",
      "Epoch 4/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0153 - val_loss: 0.2349\n",
      "Epoch 5/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0124 - val_loss: 0.2834\n",
      "Epoch 6/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0107 - val_loss: 0.2666\n",
      "Epoch 7/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0099 - val_loss: 0.2663\n",
      "Epoch 8/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0091 - val_loss: 0.2960\n",
      "Epoch 9/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0086 - val_loss: 0.3360\n",
      "Epoch 10/100\n",
      "1269/1269 - 8s - 6ms/step - loss: 0.0082 - val_loss: 0.3010\n",
      "Epoch 11/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0079 - val_loss: 0.3466\n",
      "Epoch 12/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0076 - val_loss: 0.3314\n",
      "Epoch 13/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0073 - val_loss: 0.3610\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "training model: 1\n",
      "Epoch 1/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.1833 - val_loss: 0.2298\n",
      "Epoch 2/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0393 - val_loss: 0.2096\n",
      "Epoch 3/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0225 - val_loss: 0.2372\n",
      "Epoch 4/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0170 - val_loss: 0.2319\n",
      "Epoch 5/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0142 - val_loss: 0.2673\n",
      "Epoch 6/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0124 - val_loss: 0.2781\n",
      "Epoch 7/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0112 - val_loss: 0.2936\n",
      "Epoch 8/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0103 - val_loss: 0.2788\n",
      "Epoch 9/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0097 - val_loss: 0.3042\n",
      "Epoch 10/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0093 - val_loss: 0.3043\n",
      "Epoch 11/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0089 - val_loss: 0.3069\n",
      "Epoch 12/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0086 - val_loss: 0.3530\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "training model: 2\n",
      "Epoch 1/100\n",
      "1269/1269 - 3s - 3ms/step - loss: 0.2629 - val_loss: 0.3089\n",
      "Epoch 2/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0410 - val_loss: 0.2934\n",
      "Epoch 3/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0255 - val_loss: 0.3018\n",
      "Epoch 4/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0198 - val_loss: 0.3627\n",
      "Epoch 5/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0168 - val_loss: 0.3341\n",
      "Epoch 6/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0149 - val_loss: 0.3244\n",
      "Epoch 7/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0136 - val_loss: 0.3472\n",
      "Epoch 8/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0126 - val_loss: 0.3458\n",
      "Epoch 9/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0120 - val_loss: 0.3464\n",
      "Epoch 10/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0114 - val_loss: 0.3693\n",
      "Epoch 11/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0109 - val_loss: 0.3400\n",
      "Epoch 12/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0105 - val_loss: 0.3747\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "training model: 3\n",
      "Epoch 1/100\n",
      "1269/1269 - 3s - 3ms/step - loss: 0.2178 - val_loss: 0.3266\n",
      "Epoch 2/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0492 - val_loss: 0.3190\n",
      "Epoch 3/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0291 - val_loss: 0.3030\n",
      "Epoch 4/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0216 - val_loss: 0.3205\n",
      "Epoch 5/100\n",
      "1269/1269 - 3s - 3ms/step - loss: 0.0177 - val_loss: 0.3331\n",
      "Epoch 6/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0154 - val_loss: 0.3533\n",
      "Epoch 7/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0140 - val_loss: 0.3435\n",
      "Epoch 8/100\n",
      "1269/1269 - 7s - 6ms/step - loss: 0.0129 - val_loss: 0.3125\n",
      "Epoch 9/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0122 - val_loss: 0.3668\n",
      "Epoch 10/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0116 - val_loss: 0.3560\n",
      "Epoch 11/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.0110 - val_loss: 0.3538\n",
      "Epoch 12/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0107 - val_loss: 0.3836\n",
      "Epoch 13/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0104 - val_loss: 0.4061\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "training model: 4\n",
      "Epoch 1/100\n",
      "1269/1269 - 3s - 2ms/step - loss: 0.1481 - val_loss: 0.2350\n",
      "Epoch 2/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0401 - val_loss: 0.2424\n",
      "Epoch 3/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0240 - val_loss: 0.2348\n",
      "Epoch 4/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0182 - val_loss: 0.2327\n",
      "Epoch 5/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0149 - val_loss: 0.2650\n",
      "Epoch 6/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0128 - val_loss: 0.2450\n",
      "Epoch 7/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0114 - val_loss: 0.2680\n",
      "Epoch 8/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0104 - val_loss: 0.2958\n",
      "Epoch 9/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0097 - val_loss: 0.3103\n",
      "Epoch 10/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0091 - val_loss: 0.2863\n",
      "Epoch 11/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0085 - val_loss: 0.2899\n",
      "Epoch 12/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0081 - val_loss: 0.3202\n",
      "Epoch 13/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0076 - val_loss: 0.3245\n",
      "Epoch 14/100\n",
      "1269/1269 - 2s - 2ms/step - loss: 0.0070 - val_loss: 0.3514\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "# TODO implement a more robust training setup, implement model tabulation \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(full_path, \"best_weights.keras\"), verbose=0, save_best_only=True) # save best model\n",
    "for i in range(5):\n",
    "        print(f\"training model: {i}\")\n",
    "        model = Sequential()\n",
    "        model.add(Dense(8, input_dim=x_train.shape[1], activation='relu'))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "        model.add(Dense(2, activation='sigmoid')) # single output w/o activation function b/c regression\n",
    "        model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.01, momentum=0.01))\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=2, mode='min', restore_best_weights=True)\n",
    "        history = model.fit(x_train, y_train, validation_data=(x_test, y_test),batch_size=64, callbacks=[monitor, checkpointer], verbose=2, epochs=100)\n",
    "        plot_losses(history, full_path, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505aa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step\n",
      "Log loss score: 2.928329108707056\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m file.write(metrics.classification_report(y_true, prediction))\n\u001b[32m     19\u001b[39m file.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNumpy array of predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m file.write(\u001b[33m\"\u001b[39m\u001b[33my_test:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m file.write(y_test[\u001b[32m0\u001b[39m:\u001b[32m5\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: write() argument must be str, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# load model, do prediction, do evaulation\n",
    "model.load_weights(os.path.join(full_path, \"best_weights.keras\"))\n",
    "prediction = model.predict(x_test)\n",
    "try:\n",
    "        with open(os.path.join(full_path, 'metrics.txt'), 'x') as file:\n",
    "                prediction=np.argmax(prediction, axis=1)\n",
    "                y_true = np.argmax(y_test, axis=1)\n",
    "                accuracy_score = metrics.accuracy_score(y_true, prediction)\n",
    "                precision_score = metrics.precision_score(y_true, prediction, average='weighted')\n",
    "                recall_score = metrics.recall_score(y_true, prediction, average= \"weighted\")\n",
    "                fl_score = metrics.f1_score(y_true, prediction, average= \"weighted\")\n",
    "                file.write(f\"Accuracy Score: {accuracy_score}\\n\")\n",
    "                file.write(f\"Precision Score: {precision_score}\\n\")\n",
    "                file.write(\"Recall score: {}\\n\".format(recall_score))\n",
    "                file.write(\"F1 score: {}\\n\".format(fl_score))\n",
    "                log_loss = metrics.log_loss(y_test, prediction)\n",
    "                print(\"Log loss score: {}\\n\".format(log_loss))                \n",
    "                file.write(metrics.classification_report(y_true, prediction))\n",
    "                file.write(\"\\nNumpy array of predictions\\n\")\n",
    "                file.write(np.array_str(prediction[0:5]))\n",
    "                file.write(\"y_test:\\n\")\n",
    "                file.write(np.array2string(y_test[0:5]))\n",
    "except OSError as e:\n",
    "        print(f\"Error while writing model metrics: \\n{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
